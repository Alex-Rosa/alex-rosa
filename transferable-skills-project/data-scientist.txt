Data Scientist II

Overview
Security represents the most critical priorities for our customers in a world awash in digital threats, regulatory scrutiny, and estate complexity. Microsoft Security aspires to make the world a safer place for all. We want to reshape security and empower every user, customer, and developer with a security cloud that protects them with end to end, simplified solutions. The Microsoft Security organization accelerates Microsoft’s mission and bold ambitions to ensure that our company and industry is securing digital technology platforms, devices, and clouds in our customers’ heterogeneous environments, as well as ensuring the security of our own internal estate. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. In doing so, we create life-changing innovations that impact billions of lives around the world.
Artificial Intelligence (AI) has the potential to change the world around us. At Microsoft, we are committed to the advancement of AI driven by ethical principles. We are looking for a Data Scientist II to join the AI Safety & Security platform team, focused on leveraging data to generate insights, influence strategy, and improve overall capabilities for protecting, detecting, and responding to AI incidents. This role works broadly across Microsoft on all levels of the AI stack and the teams supporting this important transformation. Are you passionate about data, the safety and security of AI, and how that intersects with our lives? This may be a great opportunity for you! 
Who we are: We are the Artificial Generative Intelligence Security (AeGIS) team, and we are charged with ensuring justified confidence in the safety of Microsoft’s generative AI products. This encompasses providing an infrastructure for AI safety; serving as a coordination point for all things AI incident response; researching the quickly evolving threat landscape; red teaming AI systems for failures; and empowering Microsoft with this knowledge. We partner closely with product engineering teams to mitigate and address the full range of threats that face AI services – from traditional security risks to novel security threats like indirect prompt injection and entirely AI-native threats like the manufacture of Non-Consensual Intimate Imagery (NCII)  or Child Sexual Abuse Material (CSAM) or the use of AI to run automated scams. We are a mission-driven team intent on delivering trustworthy AI and response processes when it does not live up to those standards. We are always learning. Insatiably curious. We lean into uncertainty, take risks, and learn quickly from our mistakes. We build on each other’s ideas, because we are better together. We are motivated every day to empower others to do and achieve more through our technology and innovation. Together we make a difference for all of our customers, from end users to Fortune 50 enterprises. Our team has people from a wide variety of backgrounds, previous work histories, and life experiences, and we are eager to maintain and grow that diversity. Our diversity of backgrounds and experiences enables us to create innovative solutions for our customers. Our culture is collaborative and customer focused.
What we do: The AI IR engineering team is part of the AI Safety & Security Platform and works alongside the front-line subject matter experts detecting and responding to incidents across Microsoft’s AI services. AI has the potential to transform our daily interaction with technology. Our team keeps the outcome focused on justified trust in Microsoft’s AI services. We are passionate about ensuring that the transformational opportunities outweigh the possible harms. When harm occurs, we address them in a timely manner. We work to consistently improve the resiliency of the systems that enable defenders to protect our AI products and services. Our team tightly partners throughout Microsoft so that we learn from and share experience in order to prevent harms before they happen. How you can help: Bring your passion for security and safety, along with your engineering experience, expertise in building scalable software solutions, and desire to be on the cutting edge of generative AI.  We collaborate closely with incident responders and security analysts to quickly build tools and automation in support of the effective resolution of AI safety and security issues. The ideal candidate will have experience shipping scalable, deeply integrated applications and tools to automate manual processes and enable new capabilities. Your passion for customer experience, ability to communicate technical details cross-functionally, and keen eye to spot opportunities to automate will aid you greatly in this role.  

Responsibilities
Provide centralized data analysis across Microsoft’s AI products to improve visibility and understanding of our overall safety and security posture.
Design and implement data pipelines and automated processes to cleanse, integrate and process large and diverse sets of AI service and security telemetry data.
Create and maintain BI dashboards and reports to provide risk analysis and insights to leadership and cross-functional stakeholders.
Influence strategic direction by tracking trends of abuse targets and techniques.
Develop and deploy ML models to classify, analyze, and handle AI-generated content at scale
Champion data-driven culture and decision-making for AI Safety and Security teams across the company.
Collaborate with Incident Responders, Analysis, PMs, and Engineers to gather requirements and ensure project success and alignment.

Required Qualifications:
Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field
OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) or consulting experience
OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 2+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) OR equivalent experience.
2+ years of experience coding in languages such as Python and/or R.
2+ years of experience with Business Intelligence reporting and tools such as PowerBI, etc.
1+ year of experience working with big data technologies like Azure Synapse, Azure Fabric, Databricks, Hadoop, etc.

Preferred Qualifications.
Doctorate/Master's/Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or a related field AND 3+ year(s) of data-science/machine learning experience (e.g., managing structured and unstructured data, applying statistical techniques, and reporting results).
Knowledge and/or experience in Generative AI.
Experience developing machine learning models to automate manual analysis steps
Experience handling large volumes of data (big data) and working with data warehouses.
Experience building and deploying solutions with Azure or similar cloud service


